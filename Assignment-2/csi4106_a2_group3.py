# -*- coding: utf-8 -*-
"""CSI4106_A2_Group3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16CbCY3tNU7crj8zeCHaY9ZLJc9aZ-qr6

**Assignment 2 - Naive Bayes and Logistic Regression**

**Group Description**

- Group Number: 3
- Member 1
  - Student Name: Meet Mehta
  - Student Number: 300261159
- Member 2
  - Student Name: Rakshita Mathur
  - Student Number: 300215340

**Importing the libraries**
"""

# Importing necessary libraries

import io
import requests
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB, CategoricalNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import MinMaxScaler
from sklearn.naive_bayes import ComplementNB
from sklearn.preprocessing import StandardScaler

"""**1. Reading the dataset**"""

# Dataset URL
url_16p = "https://raw.githubusercontent.com/rakshita003/Datasets/main/16P.csv"

# Define a custom encoding function to handle encoding issues
def custom_encoding(text):
    try:
        return text.encode('utf-8').decode('utf-8', 'ignore')
    except AttributeError:
        return text

# Fetching data from URL
response_16p = requests.get(url_16p)

#Reading the data from the CSV file
dataset = pd.read_csv(io.StringIO(response_16p.text), encoding='utf-8').applymap(custom_encoding)

type(dataset)

dataset.head()

# defining the mapping of personalities on the basis of given data
personality_mapping = {
    'ESTJ': 0,
    'ENTJ': 1,
    'ESFJ': 2,
    'ENFJ': 3,
    'ISTJ': 4,
    'ISFJ': 5,
    'INTJ': 6,
    'INFJ': 7,
    'ESTP': 8,
    'ESFP': 9,
    'ENTP': 10,
    'ENFP': 11,
    'ISTP': 12,
    'ISFP': 13,
    'INTP': 14,
    'INFP': 15
}

# Exploring the Dataset

print(dataset.info())

"""---

**2. Pre-processing Dataset**
"""

X = dataset.drop('Personality', axis =1)
y = dataset['Personality']

#encoding y-axis
dataset['Personality'] = dataset['Personality'].map(personality_mapping)

"""---

**3.Na誰ve Bayes**

- **3.1 Na誰ve Bayes with K-Fold Using GaussianNB - Default Parameter**
"""

# Splitting the data using 4-Fold Cross Validation
kf = KFold(n_splits=4)

accuracy_scores = []

#Dropping the personality column
X = dataset.drop('Personality', axis =1)

#Counter Varaible to keep track of each fold
k =1

for train_index, test_index in kf.split(dataset):
  # Split the data into training and testing sets based on the current fold
  X_train, X_test = X.iloc[train_index], X.iloc[test_index]
  y_train, y_test = dataset['Personality'].iloc[train_index], dataset['Personality'].iloc[test_index]

  #defining the classifier
  naive_bayes_classifier = GaussianNB()
  naive_bayes_classifier.fit(X_train, y_train)

  # Make predictions on the test data
  y_pred = naive_bayes_classifier.predict(X_test)
  accuracy = accuracy_score(y_test, y_pred)

  # Print accuracy for the current iteration
  print(f"Accuracy in iteration {k} is {accuracy* 100:.2f}%")
  k +=1

  # Append the accuracy to the list
  accuracy_scores.append(accuracy)

#finding the mean accuracy
avg_acc = sum(accuracy_scores) / len(accuracy_scores)


print(f'Average accuracy : {avg_acc * 100:.2f}%')

"""---

**3.2 Na誰ve Bayes with K-Fold Using GaussianNB - Hyper Parameter Tuned - Custom Prior**
"""

#Defining the custom priors. We are defining the custom prior to create a bias for each personality. Please note that the bias are assigned randomly to each personality
custom_priors = [0.05, 0.1, 0.15, 0.05, 0.025, 0.05, 0.025, 0.025, 0.025, 0.025, 0.15, 0.05, 0.025, 0.05, 0.025, 0.025]

# Calculating the sum of custom priors (will be equal to 1)
sum_of_priors = sum(custom_priors)

# Since the sum was not exactly one, we are rounding it to 1
if not np.isclose(sum_of_priors, 1.0):
    diff = 1.0 - sum_of_priors
    custom_priors[-1] += diff

naive_bayes_classifier2 = GaussianNB(priors=custom_priors)

kf = KFold(n_splits=4)

# Counter variable to keep track of each iteration
k = 1

# Initialize lists to store accuracy and confusion matrices for each fold
accuracies = []
confusion_matrices = []

# Iterate through each fold
for train_index, test_index in kf.split(dataset):
    # Split the data into training and testing sets based on the current fold
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = dataset['Personality'].iloc[train_index], dataset['Personality'].iloc[test_index]

    # Fit the classifier for this fold with custom priors
    naive_bayes_classifier2.fit(X_train, y_train)

    # Make predictions on the test data for this fold
    y_pred = naive_bayes_classifier2.predict(X_test)

    # Evaluate the classifier for this fold
    accuracy_fold = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy_fold)

    # Store the confusion matrix of this fold with a different variable name
    confusion_fold = confusion_matrix(y_test, y_pred)
    confusion_matrices.append(confusion_fold)

    print(f"Accuracy in iteration {k} is {accuracy_fold * 100:.2f}%")
    k += 1

# Calculating the mean accuracy for all folds
mean_accuracy = np.mean(accuracies)

# Printing the mean accuracy
print(f'Mean Test Accuracy: {mean_accuracy * 100:.2f}%')
print()

# Make predictions on the test data
y_pred_test = naive_bayes_classifier2.predict(X_test)

# Evaluating the classifier on the test data
accuracy_test = accuracy_score(y_test, y_pred_test)
confusion_test = confusion_matrix(y_test, y_pred_test)
classification_rep_test = classification_report(y_test, y_pred_test)

# Plot the confusion matrix for the test data
print("Confusion Matrix for Test Data:")
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_test, annot=True, fmt='d', cmap='viridis',
            xticklabels=range(10), yticklabels=range(10))
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix - Test Data')
plt.show()
print()

print(f'Test Accuracy: {accuracy_test * 100:.2f}%')
print("Classification Report for Test Data:")
print(classification_rep_test)

"""---

- **3.3 Na誰ve Bayes with K-Fold Using GaussianNB - Hyper Parameter Changed - Feature Scaling**
"""

# Splitting the data using 4-Fold Cross Validation
kf = KFold(n_splits=4)

accuracy_scores = []

# Dropping the personality column
X = dataset.drop('Personality', axis=1)

# Counter Variable to keep track of each fold
k = 1

for train_index, test_index in kf.split(dataset):
    # Split the data into training and testing sets based on the current fold
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = dataset['Personality'].iloc[train_index], dataset['Personality'].iloc[test_index]

    # Standardize the features
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Defining the classifier
    naive_bayes_classifier = GaussianNB()
    naive_bayes_classifier.fit(X_train, y_train)

    # Make predictions on the test data
    y_pred = naive_bayes_classifier.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    # Print accuracy for the current iteration
    print(f"Accuracy in iteration {k} is {accuracy * 100:.2f}%")
    k += 1

    # Append the accuracy to the list
    accuracy_scores.append(accuracy)

# Finding the mean accuracy
avg_acc = sum(accuracy_scores) / len(accuracy_scores)

print(f'Average accuracy : {avg_acc * 100:.2f}%')

"""---

**4. Logistic Regression**

**4.1 Variation-1: Hyperparameter-tuned Logistic Regression with K-Fold Cross-Validation**

In this section, a logistic regression model is created with the following hyperparameters:

- `max_iter`: Maximum number of iterations for the solver (set to 1000).
- `solver`: The solver used for optimization (set to 'lbfgs').

The code illustrates the process of logistic regression modeling, cross-validation, and hyperparameter tuning to predict personality types and assess model performance.
"""

kf = KFold(n_splits=4)

accuracy_scores_logisticRegression1 = []

X = dataset.drop('Personality', axis=1)
k = 1

for train_index, test_index in kf.split(dataset):
    # Split the data into training and testing sets based on the current fold
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = dataset['Personality'].iloc[train_index], dataset['Personality'].iloc[test_index]

    # Create a logistic regression model
    logisticRegression1 = LogisticRegression(max_iter=1000, solver='lbfgs')

    # Fit the logistic regression model to the training data
    logisticRegression1.fit(X_train, y_train)

    # Make predictions on the test data
    y_pred = logisticRegression1.predict(X_test)

    # Calculate accuracy for the current fold
    accuracy_logisticRegression1 = accuracy_score(y_test, y_pred)

    # Print accuracy for the current iteration
    print(f"Accuracy in iteration {k} is {accuracy_logisticRegression1 * 100:.2f}%")
    print()


    accuracy_scores_logisticRegression1.append(accuracy_logisticRegression1)


    conf_matrix1 = confusion_matrix(y_test, y_pred)
    # Plot the confusion matrix
    print(f'Confusion Matrix (Iteration {k})')
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix1, annot=True, fmt='d', cmap='cividis',
                xticklabels=range(10), yticklabels=range(10))
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title(f'Confusion Matrix (Iteration {k})')
    plt.show()
    print()


    class_report1 = classification_report(y_test, y_pred, output_dict=True)
    class_report_df1 = pd.DataFrame(class_report1).transpose()  # Convert to a DataFrame
    class_report_df1 = class_report_df1.applymap(lambda x: f'{x:.2f}' if isinstance(x, (float, int)) else x)  # Format to 2 decimal places
    # Print the classification report
    print(f'Classification Report (Iteration {k}):')
    print(class_report_df1)
    print()
    k += 1


avg_acc_logisticRegression1 = sum(accuracy_scores_logisticRegression1) / len(accuracy_scores_logisticRegression1)

# Print the average accuracy
print(f'Average accuracy : {avg_acc_logisticRegression1 * 100:.2f}%')

"""---

- **4.2 Variation-2: Hyperparameter-tuned Logistic Regression with K-Fold Cross-Validation**

Logistic regression model is created with the following hyperparameters:

- `max_iter`: Maximum number of iterations for the solver (set to 1000).
- `solver`: The solver used for optimization (set to 'liblinear').
- `C`: Inverse of regularization strength (set to 0.1, controlling the trade-off between fitting to the training data and regularization).
- `class_weight`: Class weights are set to 'balanced' to handle class imbalance.
- `penalty`: The penalty term for the logistic regression model is set to 'l1' for L1 regularization.

This code essentially demonstrates the process of building a logistic regression model, training it, making predictions, and evaluating its performance using accuracy, a confusion matrix, and a classification report. It also visualizes the confusion matrix using a heatmap.
"""

kf = KFold(n_splits=4)

accuracy_scores_logisticRegression2 = []

X = dataset.drop('Personality', axis=1)
k = 1

for train_index, test_index in kf.split(dataset):

    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = dataset['Personality'].iloc[train_index], dataset['Personality'].iloc[test_index]

    # Create a logistic regression model
    logisticRegression2 = LogisticRegression(max_iter=1000, solver='liblinear', C=0.1, class_weight='balanced', penalty='l1')

    # Fit the logistic regression model to the training data
    logisticRegression2.fit(X_train, y_train)

    # Make predictions on the test data
    y_pred = logisticRegression2.predict(X_test)

    accuracy_logisticRegression2 = accuracy_score(y_test, y_pred)

    # Print accuracy for the current iteration
    print(f"Accuracy in iteration {k} is {accuracy_logisticRegression2 * 100:.2f}%")
    print()

    accuracy_scores_logisticRegression2.append(accuracy_logisticRegression2)

    conf_matrix2 = confusion_matrix(y_test, y_pred)
    # Plot the confusion matrix
    print(f'Confusion Matrix (Iteration {k})')
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix2, annot=True, fmt='d', cmap='plasma',
                xticklabels=range(10), yticklabels=range(10))
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title(f'Confusion Matrix (Iteration {k})')
    plt.show()
    print()

    class_report2 = classification_report(y_test, y_pred, output_dict=True)
    class_report_df2 = pd.DataFrame(class_report2).transpose()  # Convert to a DataFrame
    class_report_df2 = class_report_df2.applymap(lambda x: f'{x:.2f}' if isinstance(x, (float, int)) else x)  # Format to 2 decimal places
    # Print the classification report
    print(f'Classification Report (Iteration {k}):')
    print(class_report_df2)
    print()
    k += 1

avg_acc_logisticRegression2 = sum(accuracy_scores_logisticRegression2) / len(accuracy_scores_logisticRegression2)

# Print the average accuracy
print(f'Average accuracy : {avg_acc_logisticRegression2 * 100:.2f}%')

"""---

- **4.3 Variation-3: Hyperparameter-tuned Logistic Regression with K-Fold Cross-Validation**


 A logistic regression model is created with specific hyperparameters, including:

 - `max_iter`: Maximum number of iterations for the solver (set to 1000).
 - `solver`: The solver used for optimization (set to 'lbfgs').
 - `C`: Inverse of regularization strength (set to 1.0, controlling the trade-off between fitting to the training data and regularization).
 - `class_weight`: Class weights are set to 'balanced' to handle class imbalance.

This code demonstrates the process of building a logistic regression model, training it, making predictions, and evaluating its performance using accuracy, a confusion matrix, and a classification report. It also visualizes the confusion matrix using a heatmap.
"""

kf = KFold(n_splits=4)

accuracy_scores_logisticRegression3 = []

X = dataset.drop('Personality', axis=1)
k = 1

for train_index, test_index in kf.split(dataset):

    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = dataset['Personality'].iloc[train_index], dataset['Personality'].iloc[test_index]

    # Create a logistic regression model
    logisticRegression3 = LogisticRegression(max_iter=1000, solver='lbfgs', C=1.0, class_weight='balanced')

    # Fit the logistic regression model to the training data
    logisticRegression3.fit(X_train, y_train)

    # Make predictions on the test data
    y_pred = logisticRegression3.predict(X_test)

    accuracy_logisticRegression3 = accuracy_score(y_test, y_pred)

    # Print accuracy for the current iteration
    print(f"Accuracy in iteration {k} is {accuracy_logisticRegression3 * 100:.2f}%")
    print()

    accuracy_scores_logisticRegression3.append(accuracy_logisticRegression3)

    conf_matrix3 = confusion_matrix(y_test, y_pred)
    # Plot the confusion matrix
    print(f'Confusion Matrix (Iteration {k})')
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix3, annot=True, fmt='d', cmap='coolwarm',
                xticklabels=range(10), yticklabels=range(10))
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title(f'Confusion Matrix (Iteration {k})')
    plt.show()
    print()

    class_report3 = classification_report(y_test, y_pred, output_dict=True)
    class_report_df3 = pd.DataFrame(class_report3).transpose()  # Convert to a DataFrame
    class_report_df3 = class_report_df3.applymap(lambda x: f'{x:.2f}' if isinstance(x, (float, int)) else x)  # Format to 2 decimal places
    # Print the classification report
    print(f'Classification Report (Iteration {k}):')
    print(class_report_df3)
    print()
    k += 1

avg_acc_logisticRegression3 = sum(accuracy_scores_logisticRegression3) / len(accuracy_scores_logisticRegression3)

# Print the average accuracy
print(f'Average accuracy : {avg_acc_logisticRegression3 * 100:.2f}%')

"""---

**5. Analysis of the obtained Result**

1. **Classifier Used:**

  - Section 3.1: Gaussian Naive Bayes - Default Parameters
  - Section 3.2: Gaussian Naive Bayes with Custom Priors
  - Section 3.3: Gaussian Naive Bayes with Feature Scaling
  - Section 4.1: Logistic Regression with 'lbfgs' Solver
  - Section 4.2: Logistic Regression with 'liblinear' Solver, Balanced Class Weights, and L1 Regularization
  - Section 4.3: Logistic Regression with 'lbfgs' Solver, Balanced Class Weights, and L2 Regularization

2. **Classifier Characteristics:**

  - Section 3 uses `Naive Bayes classifiers`, which assume feature independence.
  - Section 4 uses `Logistic Regression`, which models linear relationships between features and the target variable.

3. **Accuracies:**

  Here are the accuracies for each Section:

  1. Section 3.1: 91.04%
  2. Section 3.2: 90.08%
  3. Section 3.3: 91.00%
  4. Section 4.1: 89.41%
  5. Section 4.2: 91.32%
  6. Section 4.3: 90.01%

4. **Conclusions:**

  1. Section 3.1 (Gaussian Naive Bayes - Default), an accuracy of 91.04% was achieved. This result demonstrates capability of the Gaussian Naive Bayes algorithm to make accurate predictions.

  2. In Section 3.2 (Gaussian Naive Bayes with custom priors), an accuracy of 90.08% was achieved, showing that the custom priors do have an impact on model performance. It proved especially valuable showing prior domain knowledge favored specific class outcomes.

  3. Section 3.3 (Gaussian Naive Bayes Feature Scaling) achieved the lowest accuracy among all sections at 91.00%. This technique ensured that all features had comparable scales, enhancing the Gaussian Naive Bayes classifier's ability to make accurate predictions.

  4. In Section 4.1 (Logistic Regression with 'lbfgs' solver), the model achieved an accuracy of 89.41%, which is the lowest among all the models created for the given dataset.

  5. In Section 4.2 (Logistic Regression with 'liblinear' solver, balanced class weights, and L1 regularization), the model achieved the highest accuracy of 91.32%. This indicates that using L1 regularization and balancing class weights positively impacted the model's performance.

  6. Section 4.3 (Logistic Regression with 'lbfgs' solver, balanced class weights) achieved an accuracy of 90.01%. This result demonstrates the reliability of this logistic regression configuration.

These conclusions emphasize the importance of selecting the appropriate classifier and configuration based on the dataset's characteristics and the specific problem at hand. In this case, logistic regression with class-weight balancing and regularization (Sections 4.2 and 3.1.1) performed well, while Complement Naive Bayes (Section 3.2) demonstrated lower effectiveness.

---

**6. References:**

- [Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes)
- [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn-model-selection-kfold)
- [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)
- [Scikit Learn Tutorial](https://www.tutorialspoint.com/scikit_learn/index.htm)
- [Scikit-Learn Tutorial | Machine Learning With Scikit-Learn](https://www.youtube.com/watch?v=0Lt9w-BxKFQ&ab_channel=Simplilearn)
- [Naive Bayes Classification Tutorial using Scikit-learn](https://www.datacamp.com/tutorial/naive-bayes-scikit-learn)
-[Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)
- [Understanding Logistic Regression in Python Tutorial](https://www.datacamp.com/tutorial/understanding-logistic-regression-python)
- [Logistic Regression 3-class Classifier](https://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html#logistic-regression-3-class-classifier)

---
"""